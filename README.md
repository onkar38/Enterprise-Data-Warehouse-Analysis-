# ğŸ¥ AWS-Based Healthcare Data Lakehouse Architecture

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Spark](https://img.shields.io/badge/Apache%20Spark-3.x-orange.svg)](https://spark.apache.org/)
[![AWS](https://img.shields.io/badge/AWS-S3%20|%20Redshift%20|%20EMR-yellow.svg)](https://aws.amazon.com/)

## ğŸ¯ Project Overview

Production-grade Data Lakehouse built on AWS to process and analyze 10GB+ of semi-structured healthcare data. This project demonstrates end-to-end data engineering practices including ELT pipeline development, data lake architecture, workflow orchestration, and data warehouse modeling.

## ğŸ—ï¸ Architecture
```
[PostgreSQL] â†’ [Apache Spark/PySpark] â†’ [AWS S3 - Bronze Layer (Raw)]
                                              â†“
                                    [Spark Transformation]
                                              â†“
                                    [AWS S3 - Silver Layer (Curated)]
                                              â†“
                                    [Amazon Redshift - Star Schema]
                                              â†“
                                    [BI Dashboards]

Orchestration: Apache Airflow DAGs
Storage Format: Parquet + Snappy Compression
```

## ğŸ’» Tech Stack

- **Data Processing:** Apache Spark, PySpark
- **Cloud Platform:** AWS (S3, Redshift, EMR, EC2)
- **Orchestration:** Apache Airflow
- **Database:** PostgreSQL, Amazon Redshift
- **Storage Format:** Parquet with Snappy compression
- **Languages:** Python, SQL
- **Data Modeling:** Star Schema (Dimensional Modeling)

## ğŸš€ Key Features

- âœ… Distributed data processing with PySpark for 10GB+ datasets
- âœ… Tiered Data Lake architecture (Bronze/Silver/Gold layers)
- âœ… Automated workflow orchestration with Airflow (95% reduction in manual work)
- âœ… Optimized storage with Parquet + partitioning (40% cost reduction)
- âœ… Star Schema data warehouse in Redshift
- âœ… Fault-tolerant pipeline design
- âœ… Data quality validation and monitoring

## ğŸ“Š Results & Impact

- ğŸ“‰ **40% reduction** in S3 scanning costs through Parquet and partitioning
- âš¡ **95% reduction** in manual intervention via Airflow automation
- ğŸ¯ **85% accuracy** in patient readmission predictions
- ğŸ“ˆ Established scalable "Source of Truth" for analytics

## ğŸ“ Project Structure
```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ extract.py
â”‚   â”‚   â”œâ”€â”€ transform.py
â”‚   â”‚   â””â”€â”€ load.py
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â””â”€â”€ dags/
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â””â”€â”€ readmission_model.py
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ config/
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â””â”€â”€ README.md
```

## ğŸ”§ Setup & Installation

[Add your setup instructions here]

## ğŸ“ˆ Performance Metrics

- **Data Volume:** 10GB+ semi-structured data (JSON/CSV)
- **Processing Time:** [Add your metrics]
- **Cost Optimization:** 40% reduction in S3 costs
- **Automation:** 95% reduction in manual intervention
- **Model Accuracy:** 85% (Random Forest classifier)

## ğŸ“ Key Learnings

1. **Storage Optimization:** Parquet columnar format with Snappy compression significantly reduces both storage costs and query times
2. **Partitioning Strategy:** Proper partitioning by date columns reduces data scanning and improves query performance
3. **Airflow Orchestration:** DAG-based workflow management ensures reliability and SLA compliance
4. **Data Lake Layers:** Implementing Bronze/Silver/Gold architecture maintains data quality and lineage

## ğŸ”— Related Projects

- [Predictive Analytics Pipeline](github.com/onkar38/Health-Data-Pipeline)

## ğŸ“§ Contact

**Onkar Phopase**
- LinkedIn: [linkedin.com/in/onkar-phopase](https://linkedin.com/in/onkar-phopase)
- Email: onkarphopase026@gmail.com
- GitHub: [github.com/onkar38](https://github.com/onkar38)



â­ If you found this project helpful, please give it a star!
